---
# Site Configuration
# ==================

- hosts: all
  tasks:
    - name: determine interface
      set_fact: ipv4_address="{{ hostvars[inventory_hostname].ansible_default_ipv4.address }}"
      # eg. to use a eth1: ipv4_address="{{ hostvars[inventory_hostname].ansible_eth1.ipv4.address }}"
      tags:
        - update-hosts

- hosts: journalnodes:namenodes:resourcemanager:nodemanagers:historyserver:gateways
  sudo: true
  roles:
    - common
    - oracle_jdk
    - cdh_common
    - cdh_system_user

- hosts: journalnodes:namenodes:resourcemanager:nodemanagers:historyserver:spark_historyserver
  sudo: true
  roles:
    - cdh_hadoop_common
    - cdh_hadoop_config

- hosts: journalnodes
  sudo: true
  roles:
    - cdh_hadoop_journalnode


- hosts: namenode-primary
  sudo: true
  roles:
    - cdh_hadoop_namenode_primary
    - cdh_hadoop_zkfc

- hosts: namenode-primary
  sudo: true
  tasks:
    - name: Wait for the primary namenode to come online
      wait_for: host={{ hostvars[groups['namenode-primary'][0]]["ansible_default_ipv4"]["address"] }} port=50070
      tags:
        - install-hadoop-hdfs-namenode
        - install-hadoop-hdfs
        - install-hadoop

- hosts: namenode-standby
  sudo: true
  roles:
    - cdh_hadoop_namenode_standby
    - cdh_hadoop_zkfc

- hosts: namenode-primary
  sudo: true
  tasks:
    - name: Format hadoop-hdfs-zkfc
      sudo_user: hdfs
      shell: creates={{ item }} hdfs zkfc -formatZK -force && touch {{ item }}
      with_items:
        - /var/run/hadoop-hdfs/zkfs.formatted
      tags:
        - install-hadoop-hdfs-namenode
        - install-hadoop-hdfs-zkfs
        - install-hadoop-hdfs
        - install-hadoop
    - name: restart zkfc
      service: name=hadoop-hdfs-zkfc state=restarted
      tags:
        - install-hadoop-hdfs-namenode
        - install-hadoop-hdfs
        - install-hadoop
    - name: restart namenode
      service: name=hadoop-hdfs-namenode state=restarted
      tags:
        - install-hadoop-hdfs-namenode
        - install-hadoop-hdfs
        - install-hadoop


- hosts: datanodes
  sudo: true
  roles:
    - cdh_hadoop_datanode

- hosts: resourcemanager
  sudo: true
  roles:
    - cdh_hadoop_yarn_resourcemanager

- hosts: nodemanagers
  sudo: true
  roles:
    - cdh_hadoop_mapreduce
    - cdh_hadoop_yarn_nodemanager


- hosts: gateways
  sudo: true
  roles:
    - cdh_hadoop_gateway

- hosts: historyserver
  sudo: true
  roles:
    - cdh_hadoop_mapreduce_historyserver

- hosts: gateways:spark_historyserver
  sudo: true
  roles:
    - cdh_spark_common

- hosts: spark_historyserver
  sudo: true
  roles:
    - cdh_spark_historyserver

- hosts: resourcemanager:nodemanagers
  sudo: true
  roles:
    - cdh_hadoop_user
  vars:
    gateway: false

- hosts: gateways
  sudo: true
  roles:
    - cdh_hadoop_user
  vars:
    gateway: true
